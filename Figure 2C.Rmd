---
title: "incidence of words by pubdate"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(data.table)
library(reshape2)
library(dplyr)
library(ggplot2)
library(splus2R)
library(stringi)
library(broom)
library(lubridate)
library(tidyr)
library(mgcv)
library(forcats)
```

#### preamble
This models the *incidence* of some word in the papers published at some date. So: choose a word and a date, examine the papers published at that date, and it tells you the frequency of that word among them.

#### data
get the word count data
```{r}
a<-fread("women_counts_allpapers.csv")
b<-fread("supertopic_counts_allpapers.csv")
`````

`````{r}
a1<-a%>%
select(paper_id, N_present, N_absent, N_all)
b1<-b%>%
select("paper_id", "dec_pub_date","year","topic_class","topic_class_no","women", "standprob", "present_05")
```````
remove all papers with a woman-specific topic
````{r}
nw<-b1%>%
group_by(paper_id)%>%
filter(present_05==1)%>%
summarize(aboutwomen=sum(women))%>%
  filter(aboutwomen==0)
``````
select papers that are not about women

`````{r}
b2<-b1%>%
filter(paper_id%in%nw$paper_id)
length(unique(b2$paper_id))
```````

identify 9 interesting clinical topics
`````{r}
unique(b2$topic_class)
count<-b1%>%
  group_by(topic_class)%>%
  summarize(N_papers=sum(present_05))%>%
  arrange(desc(N_papers))
as.data.frame(count)

select=c("cardiology", "haematology", "endocrinology", "pharmacology", "neurology", "psychiatry", "nephrology", "oncology", "addiction", "gastroenterology", "ear_nose_throat", "anaesthesiology", "radiology", "clinical_research_trial", "accidents_trauma", "pulmonology")
b3<-b2%>%
  filter(topic_class%in%select)
```````
merge with women word count data
``````{r}
b4<-merge(b3, a1, by="paper_id")
````````
keep only papers for which the supertopics are present

````{r}
b4<-b4%>%
filter(present_05==1)
```````
get counts by dec_pub_date and supertopic
```{r}
b5<-b4%>%
group_by(topic_class, dec_pub_date)%>%
summarize(N_present=sum(N_present), N_absent=sum(N_absent))
b6<-b5[complete.cases(b5),]
````

now get yearly counts
````````````{r}
b6<-b4%>%
group_by(topic_class, year)%>%
summarize(N_women=sum(N_present), N_all=sum(N_all))
b6$F_women=b6$N_women/b6$N_all
b6$se = sqrt(b6$F_women*(1-b6$F_women)/b6$N_all)
b6$error<-qnorm(0.975)*b6$se
````````````````

now get decade counts
````````````{r}
b4$decade<-floor(b4$year/10)*10
b7<-b4%>%
group_by(topic_class, decade)%>%
summarize(N_women=sum(N_present), N_all=sum(N_all))
b7$F_women=b7$N_women/b7$N_all
b7$se = sqrt(b7$F_women*(1-b7$F_women)/b7$N_all)
b7$error<-qnorm(0.975)*b7$se
````````````````
This runs the glm and extracts all the coefficients.
``````{r}
glmcoefs<-b5%>% 
group_by(topic_class)%>%
do(glm(cbind(N_present, N_absent) ~ dec_pub_date, family=binomial, data = .)
%>%coef %>% as_data_frame)
glmcoefs<-as.data.frame(glmcoefs)
glmcoefs$effect<-c("intercept", "dec_pub_date")
glmcoefs<-dcast(glmcoefs, topic_class~effect, value.var="value")%>%
arrange(desc(dec_pub_date))
``````````
note that these exponents are log odds; we have to exponentiate to get odds ratios
````````{r}
glmcoefs$dec_pub_date_odds<-exp(glmcoefs$dec_pub_date)
glmcoefs<-glmcoefs%>%
arrange(desc(dec_pub_date_odds))
head(glmcoefs)
tail(glmcoefs)
``````
get the confidence intervals
`````{r}
glmconfint<-b5%>% 
group_by(topic_class)%>%
do(glm(cbind(N_present, N_absent) ~ dec_pub_date, family=binomial, data = .)
%>%confint %>% as_data_frame)
glmconfint$term<-c("intercept", "dec_pub_date")
glmconfint<-glmconfint%>%
filter(term=="dec_pub_date")
names(glmconfint)<-c("topic_class", "LCI", "UCI", "term")
glmconfint$LCI_odds<-exp(glmconfint$LCI)
glmconfint$UCI_odds<-exp(glmconfint$UCI)
`````
merge with estimates
``````{r}
glmcoefs<-glmcoefs%>%
select(topic_class, dec_pub_date_odds)
glmconfint1<-glmconfint%>%
select(topic_class, LCI_odds, UCI_odds)
glmconfint2<-merge(glmcoefs, glmconfint1, by="topic_class")%>%
  arrange(desc(dec_pub_date_odds))
glmconfint2$CI<-(glmconfint2$UCI_odds-glmconfint2$LCI_odds)/2
glmconfint2
``````
This function re-runs the model and gets the predictions
``````{r}
one_topic_class<-function(one_topic_class){
model<- glm(cbind(N_present, N_absent) ~ dec_pub_date, data=one_topic_class,  family=binomial)
dec_pub_date<-sort(unique(b5$dec_pub_date))
pred<-as.data.frame(dec_pub_date)
p1<-predict(model,pred,se=TRUE, type="response")
pred$fit<-p1$fit
pred$se<-p1$se
return(pred)
}
`````````
This re-runs the model over all topic_classes and gets the predictions
`````````{r}
r1<-b5%>%
group_by(topic_class)%>%
do(one_topic_class(.))
r3<-as.data.frame(r1)
`````````
sort out the plotting order
````{r}
o<-glmconfint2%>%
select("topic_class")
o$order<-1:nrow(o)
r3<-merge(r3, o)
r3$topic_class<-as.factor(r3$topic_class)
r3$topic_class<- reorder(r3$topic_class, r3$order)
levels(r3$topic_class)
b6<-merge(b6, o)
b6$topic_class<- reorder(b6$topic_class, b6$order)
levels(b6$topic_class)
``````
plot
```````{r}
#make 5 x 5 inches
godlee<-decimal_date(as.Date("2005-03-01"))
ggplot()+
geom_point(data=b6, aes(x=year, y=F_women), alpha=0.5, colour="grey75", size=2)+
geom_errorbar(data=b6, aes(x=year, ymin=F_women-error, ymax=F_women+error), alpha=0.5, colour="grey75", size=1, width=2)+
#first glm  
geom_line(data=r3, aes(x=dec_pub_date, y=fit), alpha=1, size=1, colour="grey50")+
geom_ribbon(data=r3, aes(x=dec_pub_date, ymin=fit-se, ymax=fit+se),alpha=0.5, size=1, fill="grey25")+
theme_classic()+
#scale_y_continuous(limits=c(0, 0.012), breaks = seq(0, 0.012, by = 0.002))+
scale_x_continuous(breaks = seq(1945, 2015, by = 10))+
ylab("incidence")+
theme(aspect.ratio=1)+
#geom_hline(yintercept = 0, colour="grey50", size=1)+
geom_vline(xintercept=godlee, colour="grey50", size=1, linetype="dotted")+
facet_wrap(~topic_class, ncol=3, scales="free_y")
``````````
plot
```{r}
library(wesanderson)
pal <- wes_palette("GrandBudapest1", 20, type = "continuous")
```````

```````{r}
r3$topic_class<- reorder(r3$topic_class, r3$order)
levels(r3$topic_class)
#make 5 x 5 inches
godlee<-decimal_date(as.Date("2005-03-01"))
ggplot()+
geom_line(data=r3, aes(x=dec_pub_date, y=fit, colour=as.factor(topic_class)), alpha=1, size=1)+
geom_ribbon(data=r3, aes(x=dec_pub_date, ymin=fit-se, ymax=fit+se, fill=as.factor(topic_class)),alpha=0.5, size=1)+
theme_classic()+
scale_color_manual(values = c(pal))+
scale_fill_manual(values = c(pal))+
scale_y_continuous(limits=c(0, 0.007), breaks = seq(0, 0.007, by = 0.001))+
scale_x_continuous(breaks = seq(1945, 2015, by = 10))+
ylab("incidence")+
theme(aspect.ratio=1)+
geom_vline(xintercept=godlee, colour="grey50", size=1, linetype="dotted")
``````````

# miscellany
check glm coeffs
````{r}
glmconfint2$sig<-ifelse(glmconfint2$dec_pub_date_odds >1 & glmconfint2$LCI_odds>1, "sig", 
ifelse(glmconfint2$dec_pub_date_odds <1 & glmconfint2$UCI_odds<1,"sig", "NS"))
glmconfint2
```
fraction of women-specific papers by field
identify papers about women
```{r}
wom<-b1%>%
group_by(paper_id)%>%
filter(present_05==1)%>%
mutate(N_womentopics=sum(women))%>%
arrange(desc(N_womentopics, paper_id))
wom$about_women<-ifelse(wom$N_womentopics>0, 1,0)
```
now remove women topics and the number of papers in each topic class that do or do not mention women
```{r}
wom1<-wom%>%
filter(women!=1)%>%
group_by(topic_class, about_women)%>%
filter(present_05==1)%>%
summarize(N_papers=length(paper_id))
```
get fraction of papers in each field about women and calculate CIs
```{r}
wom2<-dcast(wom1, topic_class~about_women, value.var="N_papers")
names(wom2)<-c("topic_class", "N_papers_not_women", "N_papers_women")
wom2$N_papers_total<-wom2$N_papers_not_women+wom2$N_papers_women
wom2$F_papers_women<-wom2$N_papers_women/wom2$N_papers_tota
wom2<-wom2%>%
  filter(topic_class%in%select)%>%
  arrange(desc(F_papers_women))
wom2$se<-sqrt((wom2$F_papers_women*(1-wom2$F_papers_women))/wom2$N_papers_total)
z_star = round(qnorm((1-0.95)/2,lower.tail=F),digits=2)
wom2$CI<-wom2$se*z_star
wom2<-wom2%>%
    select("topic_class", "N_papers_women", "N_papers_total", "F_papers_women", "CI")
wom2$F_papers_women<-round(wom2$F_papers_women,3)
wom2$CI<-round(wom2$CI,3)
wom2
```



